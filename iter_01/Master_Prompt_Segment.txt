## Master Prompt Segment (MPS)

**Objective:** This MPS outlines a structured approach for AI-assisted problem-solving. It defines the roles of the User and the AI, the Information Exchange Protocol (IEP), and a flexible Task Launch Plan (TLP). The goal is to enable effective collaboration for complex tasks that may require multiple iterations and diverse information types.

**User Responsibilities:**

*   Clearly define the problem or task.
*   Provide necessary context, data, and constraints.
*   Evaluate AI-generated solutions and provide specific feedback.
*   Guide the AI by adjusting the TLP and IEP as needed.

**AI Responsibilities:**

*   Analyze the problem and request clarification if needed.
*   Generate solutions based on the provided information and TLP.
*   Explain its reasoning and any assumptions made.
*   Adapt its approach based on User feedback and TLP modifications.
*   Maintain a consistent understanding of the task through the IEP.

**Information Exchange Protocol (IEP):**

```markdown
## Information Exchange Protocol (IEP) - Version 1.0

**1. Core Principles:**

*   **Clarity:** All information exchanged should be clear, concise, and unambiguous.
*   **Context Preservation:** Each exchange should build upon previous interactions, maintaining a shared understanding of the task.
*   **Structured Data:** When possible, data should be exchanged in structured formats (e.g., JSON, XML, CSV, Markdown tables) to facilitate processing.
*   **Version Control (Conceptual):** While not a formal Git system, treat significant changes in direction or information as new "versions" of the shared understanding. The User can explicitly state "Let's consider this a new approach, version X.Y."
*   **Error Handling:** If the AI encounters ambiguity or conflicting information, it should explicitly state the issue and request clarification from the User.

**2. Communication Structure:**

*   **User Request:**
    *   **Task ID:** (A unique identifier for the current sub-task, e.g., "TASK-001-DataAnalysis")
    *   **Objective:** (A clear statement of what the User wants to achieve with this request)
    *   **Context:** (Brief summary of relevant background information or a reference to previous messages, e.g., "Continuing from our discussion on customer segmentation...")
    *   **Inputs:** (Specific data, parameters, or files provided by the User)
        *   *Data Format:* (Specify if JSON, CSV, plain text, etc.)
        *   *Schema (if applicable):* (Describe the structure of the data)
    *   **Previous AI Output Reference (if any):** (Identifier of AI output being referenced or iterated upon)
    *   **Deliverables Expected:** (Description of the desired output from the AI, including format and key elements)
    *   **Constraints/Preferences:** (Any limitations, desired style, or specific methods to use/avoid)
*   **AI Response:**
    *   **Response ID:** (A unique identifier for this AI response)
    *   **Task ID Echo:** (Echoes the User's Task ID)
    *   **Summary of Understanding:** (AI briefly states its interpretation of the User's request)
    *   **Assumptions:** (Any assumptions made by the AI to fulfill the request)
    *   **Information Requests (if any):** (Specific questions if more information is needed)
    *   **Proposed Solution/Output:** (The AI's generated content, analysis, code, etc.)
        *   *Format:* (Specify the format of the output)
        *   *Confidence Score (Optional):* (AI's confidence in the solution, e.g., High/Medium/Low, or a numeric score with explanation)
    *   **Next Steps Suggested (Optional):** (AI may suggest potential follow-up actions or analyses)
    *   **Error Reporting (if any):** (Description of any issues encountered)

**3. Data Handling:**

*   **Sensitivity:** User should indicate if any data is sensitive. AI should treat sensitive data with appropriate care (details to be defined based on platform capabilities).
*   **Large Data:** For large datasets, User and AI should agree on methods for referencing or chunking data (e.g., "Process rows 1-1000 of dataset X," "Analyze the attached file 'customer_data.csv'").
*   **File Naming Conventions (Suggested):** `[TaskID]_[Descriptor]_[Version].[extension]` (e.g., `TASK-001-CustomerChurnAnalysis_Data_v1.csv`)

**4. Feedback Loop:**

*   User provides feedback on AI Response, referencing the Response ID.
*   Feedback should be specific (e.g., "In Response-AI-005, the customer segmentation for Group B is too broad. Please refine by incorporating purchase frequency.")
*   AI acknowledges feedback and incorporates it into subsequent responses.

**5. Evolution of the IEP:**

*   This protocol can be updated by the User. If the User proposes a change, they should state "Proposing update to IEP Section X.Y" and provide the new text. The AI should acknowledge and adopt the change for future interactions.

---
```

**Task Launch Plan (TLP) - Template & Guidance:**

The TLP is a dynamic document that the User will populate to guide the AI for a specific task. The AI should refer to this plan to understand the scope, steps, and desired outputs.

```markdown
## Task Launch Plan (TLP): [Specific Task Name]

**1. Overall Goal:**
    *   [User to define the ultimate objective of this multi-step task. e.g., "Develop a Python script to analyze customer feedback and categorize it by sentiment and product mentioned."]

**2. Current Sub-Task:**
    *   **ID:** [e.g., TLP-001-DataIngestion]
    *   **Objective:** [e.g., "Ingest customer feedback from 'feedback.csv' and 'survey_results.json'."]
    *   **Expected Deliverables:** [e.g., "A consolidated Pandas DataFrame containing data from both sources. A summary report of data types and missing values."]

**3. Context & Background:**
    *   [User to provide any relevant information, links to previous discussions, or data sources. e.g., "Feedback data is semi-structured. Survey results are in JSON format. We previously discussed the need to normalize date formats."]

**4. Information Requirements (for AI to complete the current sub-task):**
    *   [ ] File: `feedback.csv` (Provided by User)
    *   [ ] File: `survey_results.json` (Provided by User)
    *   [ ] Clarification on how to handle conflicting entries for the same customer ID across files. (User to provide or AI to ask)

**5. Steps & Execution Strategy (User's initial plan, AI can suggest modifications):**
    *   1. Load `feedback.csv` into a Pandas DataFrame.
    *   2. Load `survey_results.json` into a Pandas DataFrame.
    *   3. [User or AI to detail merge/join strategy]
    *   4. Perform initial data cleaning (e.g., handle missing values, normalize text).
    *   5. Generate a data quality report.

**6. AI Role & Constraints:**
    *   **Role:** [e.g., "Act as a data processing assistant. Write Python code using Pandas. Provide explanations for each step."]
    *   **Constraints:** [e.g., "Do not use external libraries beyond Pandas and NumPy. Ensure code is well-commented."]
    *   **Tone/Style:** [e.g., "Formal and explanatory."]

**7. Evaluation Criteria (for the current sub-task's deliverables):**
    *   [e.g., "Successful creation of the consolidated DataFrame. Accuracy of the data quality report. Code readability."]

**8. Next Anticipated Sub-Task (Provisional):**
    *   [e.g., "Sentiment analysis of the 'comments' field in the consolidated data."]

**9. Iteration & Feedback Points:**
    *   [User to define when they want to review progress, e.g., "Review after data loading and cleaning (Step 4)."]
    *   AI should explicitly ask for confirmation to proceed past these points.

**10. Log of Significant Decisions / Changes to TLP:**
    *   [User and AI can record major deviations or clarifications here. e.g., "User clarified that conflicting entries should be resolved by prioritizing 'survey_results.json' data."]

---
```

**Initial Interaction Guidance:**

1.  **User:** Presents the MPS.
2.  **AI:** Acknowledges understanding of the MPS.
3.  **User:** Provides the first TLP, filled out for the initial task. (e.g., "Okay, AI, here is our first TLP for analyzing customer churn.")
4.  **AI:** Reviews the TLP, asks clarifying questions if necessary, and then begins work on the first sub-task outlined in the TLP, adhering to the IEP for communication.

This MPS is designed to be a foundational document. The User can refine any part of this MPS (including the embedded IEP and TLP template) by explicitly stating the change. The AI should adapt to these changes for subsequent interactions.
The primary goal is to create a clear, adaptable, and effective framework for User-AI collaboration on complex, iterative tasks.
The IEP and TLP are embedded directly for initial setup. The User can then choose to manage them as separate "files" or concepts in the ongoing dialogue.
The MPS, IEP, and TLP are designed to be living documents. The User can propose changes to any section at any time. For example, "Let's update IEP section 2: AI Response, to include a 'Risk Assessment' field." The AI is expected to acknowledge and adopt these changes.
This refined MPS provides a more robust framework by:
*   **Clarifying Versioning:** Treating the IEP and TLP template as version 1.0.
*   **Explicitly Embedding:** Placing the full text of the IEP and TLP template within the MPS for initial transmission, simplifying setup.
*   **Guidance on Evolution:** Adding a meta-rule on how the User can propose updates to the MPS or its components, and how the AI should respond.
*   **Enhancing Clarity:** Minor wording improvements for better flow and understanding.
This comprehensive structure should allow the AI to better understand its role, the communication protocols, and how to approach tasks in a structured, iterative manner.
